{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7815af7af69f60e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:47.107547Z",
     "start_time": "2023-11-21T19:35:45.712508Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:47.118509Z",
     "start_time": "2023-11-21T19:35:47.109569Z"
    }
   },
   "id": "12b79a6c06694f92"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:47.118769Z",
     "start_time": "2023-11-21T19:35:47.113548Z"
    }
   },
   "id": "5a088d0e8dead3f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a59fabd441d22859"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/IoT_Modbus.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:47.304551Z",
     "start_time": "2023-11-21T19:35:47.116071Z"
    }
   },
   "id": "969c8f8886dbef26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Complete EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aee1e602ca5c766b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine 'date' and 'time' into a single datetime column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a9dccfe7b750f4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/28c_j79n3zn_3rkwzsdcmn240000gn/T/ipykernel_8295/2882021498.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n"
     ]
    }
   ],
   "source": [
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.846929Z",
     "start_time": "2023-11-21T19:35:47.305562Z"
    }
   },
   "id": "b0c2e5922a26caa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract time features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a533a2b1f01a79"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['minute'] = data['datetime'].dt.minute\n",
    "data['second'] = data['datetime'].dt.second\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.880985Z",
     "start_time": "2023-11-21T19:35:52.847618Z"
    }
   },
   "id": "c0beb939e4303617"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time series models need to ensure that the data set is arranged in time order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfdf8be0feb86374"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Sort the data by datetime\n",
    "data = data.sort_values(by='datetime')\n",
    "\n",
    "# Drop the original date, time, and timestamp columns\n",
    "data.drop(['date', 'time', 'datetime', 'type'], axis=1, inplace=True)\n",
    "\n",
    "# Adjust feature order\n",
    "order = ['year', 'month', 'day', 'hour', 'minute', 'second', 'dayofweek', 'FC1_Read_Input_Register', 'FC2_Read_Discrete_Value', 'FC3_Read_Holding_Register', 'FC4_Read_Coil', 'label']\n",
    "data = data[order].astype('int32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.928273Z",
     "start_time": "2023-11-21T19:35:52.880642Z"
    }
   },
   "id": "87cbc212dbe19442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset (Sequential Split)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "347aaeb8bf6dd766"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Calculate split points\n",
    "split_idx = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data set, keeping order\n",
    "train_data = data.iloc[:split_idx]\n",
    "test_data = data.iloc[split_idx:]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.936089Z",
     "start_time": "2023-11-21T19:35:52.933731Z"
    }
   },
   "id": "7f9a3e7015aaf6cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing (Normalization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f2fffdb83cab7f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 229755 entries, 541 to 184368\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   year                       229755 non-null  float32\n",
      " 1   month                      229755 non-null  float32\n",
      " 2   day                        229755 non-null  float32\n",
      " 3   hour                       229755 non-null  float32\n",
      " 4   minute                     229755 non-null  float32\n",
      " 5   second                     229755 non-null  float32\n",
      " 6   dayofweek                  229755 non-null  float32\n",
      " 7   FC1_Read_Input_Register    229755 non-null  float32\n",
      " 8   FC2_Read_Discrete_Value    229755 non-null  float32\n",
      " 9   FC3_Read_Holding_Register  229755 non-null  float32\n",
      " 10  FC4_Read_Coil              229755 non-null  float32\n",
      "dtypes: float32(11)\n",
      "memory usage: 11.4 MB\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in X_train.columns if col != 'label']\n",
    "scaler = MinMaxScaler()\n",
    "X_train[feature_columns] = scaler.fit_transform(X_train[feature_columns]).astype('float32')\n",
    "X_test[feature_columns] = scaler.transform(X_test[feature_columns]).astype('float32')\n",
    "X_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.973255Z",
     "start_time": "2023-11-21T19:35:52.940819Z"
    }
   },
   "id": "485e69a0e89e7b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execution model\n",
    "## Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c12c1b7fb50ea4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class LightweightLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, width_multiplier=1.0):\n",
    "        super(LightweightLSTM, self).__init__()\n",
    "        # Adjust hidden size based on the width multiplier\n",
    "        adjusted_hidden_size = int(hidden_size * width_multiplier)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, adjusted_hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(adjusted_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        # Take the output of the last time step\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "\n",
    "        # Output layer\n",
    "        out = self.fc(last_time_step_out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.973486Z",
     "start_time": "2023-11-21T19:35:52.969455Z"
    }
   },
   "id": "2ef4fe25ff764a21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3417f767ae1b5015"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "features_num = X_train.shape[1]\n",
    "hidden_neurons_num = 512\n",
    "output_neurons_num = 1\n",
    "lstm_num_layers = 2\n",
    "multiplier = 0.5\n",
    "\n",
    "model = LightweightLSTM(features_num, hidden_neurons_num, output_neurons_num, lstm_num_layers, multiplier).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:52.980509Z",
     "start_time": "2023-11-21T19:35:52.972210Z"
    }
   },
   "id": "2d66654954854fc2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:53.018632Z",
     "start_time": "2023-11-21T19:35:52.978098Z"
    }
   },
   "id": "5dd5b70589db43fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build loss functions and optimizers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da11cc42cf71b4f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "weights = torch.tensor([1, class_weights[1]], dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(torch.FloatTensor ([weights[1] / weights[0]])).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:53.026007Z",
     "start_time": "2023-11-21T19:35:52.994866Z"
    }
   },
   "id": "f491c38526ef20b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct Data Loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b12e726d70842c15"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "X_train_tensor = torch.tensor(X_train.values).float().unsqueeze(1).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values).float().unsqueeze(1).to(device)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:35:53.026210Z",
     "start_time": "2023-11-21T19:35:52.999682Z"
    }
   },
   "id": "578fb1053dfb20ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677881d18ae0a8bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5964092749277182, Accuracy: 0.8649068593314764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:12<20:22, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [2/100], Loss: 0.6697538053469778, Accuracy: 0.8352324164345404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:24<19:53, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [3/100], Loss: 0.6841559864119013, Accuracy: 0.8446204735376045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:36<19:20, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [4/100], Loss: 0.6319667941687636, Accuracy: 0.8554535167130919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:47<18:55, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [5/100], Loss: 0.6062442797480067, Accuracy: 0.8665389972144847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:59<18:36, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [6/100], Loss: 0.5614399757185735, Accuracy: 0.8753830083565459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:10<18:15, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [7/100], Loss: 0.5116179810095153, Accuracy: 0.8955562325905293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:22<17:59, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [8/100], Loss: 0.5134656784693081, Accuracy: 0.8870778203342619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:34<17:53, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [9/100], Loss: 0.6041127104192278, Accuracy: 0.8602759401114206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:45<17:44, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n",
      "Epoch [10/100], Loss: 0.6575821128615906, Accuracy: 0.8291303969359332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:57<17:34, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1377461306777625 , Precision:  0.1377461306777625 , Recall:  1.0 , F1:  0.24213860537711743\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "pbar = tqdm(total=num_epochs)\n",
    "loss_list = [None] * num_epochs\n",
    "acc_list = [None] * num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    times = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        # FP\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # BP and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate indicators\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "            # Calculate indicators\n",
    "            y = labels.cpu().numpy()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += accuracy_score(y, predictions)\n",
    "            times += 1\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = running_accuracy / times\n",
    "    loss_list[epoch] = epoch_loss\n",
    "    acc_list[epoch] = accuracy\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Accuracy: {accuracy}')\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test.values).float().unsqueeze(1).to(device)\n",
    "    model.eval()\n",
    "    outputs = model(X_test_tensor)\n",
    "    with torch.no_grad():\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "    \n",
    "        # Calculate indicators\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions)\n",
    "        recall = recall_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "        print(\"Accuracy: \", acc, \", Precision: \", precision, \", Recall: \", recall, \", F1: \", f1)\n",
    "    pbar.update(1)\n",
    "pbar.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:35:53.006686Z"
    }
   },
   "id": "234ca3f008e97e4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualizing the training process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a90b287ae5db1a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Draw accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(acc_list, label='Training Accuracy')\n",
    "plt.title('Training Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7bab09ae6142362b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unseen test set performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bc101f20737968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test.values).float().unsqueeze(1).to(device)\n",
    "\n",
    "model.eval()\n",
    "outputs = model(X_test_tensor)\n",
    "with torch.no_grad():\n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "    # Calculate indicators\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy: \", acc, \", Precision: \", precision, \", Recall: \", recall, \", F1: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ff3af552cbe05e41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37bb5c5380a6d9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_folder = \"save_model\"\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_filename = f\"model_rnn_{current_time}.pt\"\n",
    "full_path = os.path.join(save_folder, model_filename)\n",
    "torch.save(model.state_dict(), full_path)\n",
    "\n",
    "print(\"Model saved as:\", full_path)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e0e155fdfdd5bb14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
