{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7815af7af69f60e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:39.653194Z",
     "start_time": "2023-11-21T19:55:38.066246Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:39.660965Z",
     "start_time": "2023-11-21T19:55:39.654273Z"
    }
   },
   "id": "12b79a6c06694f92"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:39.661139Z",
     "start_time": "2023-11-21T19:55:39.658870Z"
    }
   },
   "id": "5a088d0e8dead3f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a59fabd441d22859"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/IoT_Modbus.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:39.843653Z",
     "start_time": "2023-11-21T19:55:39.660660Z"
    }
   },
   "id": "969c8f8886dbef26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Complete EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aee1e602ca5c766b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine 'date' and 'time' into a single datetime column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a9dccfe7b750f4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/28c_j79n3zn_3rkwzsdcmn240000gn/T/ipykernel_8451/2882021498.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n"
     ]
    }
   ],
   "source": [
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.216086Z",
     "start_time": "2023-11-21T19:55:39.844573Z"
    }
   },
   "id": "b0c2e5922a26caa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract time features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a533a2b1f01a79"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['minute'] = data['datetime'].dt.minute\n",
    "data['second'] = data['datetime'].dt.second\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.246546Z",
     "start_time": "2023-11-21T19:55:45.216805Z"
    }
   },
   "id": "c0beb939e4303617"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time series models need to ensure that the data set is arranged in time order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfdf8be0feb86374"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Sort the data by datetime\n",
    "data = data.sort_values(by='datetime')\n",
    "\n",
    "# Drop the original date, time, and timestamp columns\n",
    "data.drop(['date', 'time', 'datetime', 'type'], axis=1, inplace=True)\n",
    "\n",
    "# Adjust feature order\n",
    "order = ['year', 'month', 'day', 'hour', 'minute', 'second', 'dayofweek', 'FC1_Read_Input_Register', 'FC2_Read_Discrete_Value', 'FC3_Read_Holding_Register', 'FC4_Read_Coil', 'label']\n",
    "data = data[order].astype('int32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.291392Z",
     "start_time": "2023-11-21T19:55:45.248062Z"
    }
   },
   "id": "87cbc212dbe19442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset (Sequential Split)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "347aaeb8bf6dd766"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Calculate split points\n",
    "split_idx = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data set, keeping order\n",
    "train_data = data.iloc[:split_idx]\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = data.iloc[split_idx:]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.311681Z",
     "start_time": "2023-11-21T19:55:45.292605Z"
    }
   },
   "id": "7f9a3e7015aaf6cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing (Normalization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f2fffdb83cab7f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229755 entries, 0 to 229754\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   year                       229755 non-null  float32\n",
      " 1   month                      229755 non-null  float32\n",
      " 2   day                        229755 non-null  float32\n",
      " 3   hour                       229755 non-null  float32\n",
      " 4   minute                     229755 non-null  float32\n",
      " 5   second                     229755 non-null  float32\n",
      " 6   dayofweek                  229755 non-null  float32\n",
      " 7   FC1_Read_Input_Register    229755 non-null  float32\n",
      " 8   FC2_Read_Discrete_Value    229755 non-null  float32\n",
      " 9   FC3_Read_Holding_Register  229755 non-null  float32\n",
      " 10  FC4_Read_Coil              229755 non-null  float32\n",
      "dtypes: float32(11)\n",
      "memory usage: 9.6 MB\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in X_train.columns if col != 'label']\n",
    "scaler = StandardScaler()\n",
    "X_train[feature_columns] = scaler.fit_transform(X_train[feature_columns]).astype('float32')\n",
    "X_test[feature_columns] = scaler.transform(X_test[feature_columns]).astype('float32')\n",
    "X_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.347035Z",
     "start_time": "2023-11-21T19:55:45.315697Z"
    }
   },
   "id": "485e69a0e89e7b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execution model\n",
    "## Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c12c1b7fb50ea4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class LightweightMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_size):\n",
    "        super(LightweightMLP, self).__init__()\n",
    "        \n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        temp = F.relu(self.linear_1(x))\n",
    "        return self.linear_2(temp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.347180Z",
     "start_time": "2023-11-21T19:55:45.343296Z"
    }
   },
   "id": "2ef4fe25ff764a21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3417f767ae1b5015"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LightweightMLP.__init__() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m lstm_num_layers \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      5\u001B[0m multiplier \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[0;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mLightweightMLP\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_neurons_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_neurons_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultiplier\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mTypeError\u001B[0m: LightweightMLP.__init__() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "features_num = X_train.shape[1]\n",
    "hidden_neurons_num = 512\n",
    "output_neurons_num = 1\n",
    "lstm_num_layers = 2\n",
    "multiplier = 0.5\n",
    "\n",
    "model = LightweightMLP(features_num, hidden_neurons_num, output_neurons_num, multiplier).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.643787Z",
     "start_time": "2023-11-21T19:55:45.345964Z"
    }
   },
   "id": "2d66654954854fc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T19:55:45.648453Z",
     "start_time": "2023-11-21T19:55:45.645267Z"
    }
   },
   "id": "5dd5b70589db43fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build loss functions and optimizers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da11cc42cf71b4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = torch.tensor([1, class_weights[1]], dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(torch.FloatTensor ([weights[1] / weights[0]])).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.646451Z"
    }
   },
   "id": "f491c38526ef20b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct Data Loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b12e726d70842c15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "X_train_tensor = torch.tensor(X_train.values).float().to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values).float().to(device)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.647828Z"
    }
   },
   "id": "578fb1053dfb20ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677881d18ae0a8bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "pbar = tqdm(total=num_epochs)\n",
    "loss_list = [None] * num_epochs\n",
    "acc_list = [None] * num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    times = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        # FP\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # BP and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate indicators\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "            # Calculate indicators\n",
    "            y = labels.cpu().numpy()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += accuracy_score(y, predictions)\n",
    "            times += 1\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = running_accuracy / times\n",
    "    loss_list[epoch] = epoch_loss\n",
    "    acc_list[epoch] = accuracy\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Accuracy: {accuracy}')\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test.values).float().unsqueeze(1).to(device)\n",
    "    model.eval()\n",
    "    outputs = model(X_test_tensor)\n",
    "    with torch.no_grad():\n",
    "        probabilities = torch.sigmoid(outputs).squeeze()\n",
    "        predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "    \n",
    "        # Calculate indicators\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions)\n",
    "        recall = recall_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "        print(\"Accuracy: \", acc, \", Precision: \", precision, \", Recall: \", recall, \", F1: \", f1)\n",
    "    pbar.update(1)\n",
    "pbar.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.648963Z"
    }
   },
   "id": "234ca3f008e97e4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualizing the training process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a90b287ae5db1a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Draw accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(acc_list, label='Training Accuracy')\n",
    "plt.title('Training Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.649712Z"
    }
   },
   "id": "7bab09ae6142362b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unseen test set performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bc101f20737968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test.values).float().unsqueeze(1).to(device)\n",
    "\n",
    "model.eval()\n",
    "outputs = model(X_test_tensor)\n",
    "with torch.no_grad():\n",
    "    probabilities = torch.sigmoid(outputs).squeeze()\n",
    "    predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "    # Calculate indicators\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy: \", acc, \", Precision: \", precision, \", Recall: \", recall, \", F1: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.650456Z"
    }
   },
   "id": "ff3af552cbe05e41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37bb5c5380a6d9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_folder = \"save_model\"\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_filename = f\"model_rnn_{current_time}.pt\"\n",
    "full_path = os.path.join(save_folder, model_filename)\n",
    "torch.save(model.state_dict(), full_path)\n",
    "\n",
    "print(\"Model saved as:\", full_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T19:55:45.651075Z"
    }
   },
   "id": "e0e155fdfdd5bb14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
