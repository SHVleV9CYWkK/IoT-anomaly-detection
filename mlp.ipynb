{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7815af7af69f60e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12b79a6c06694f92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a088d0e8dead3f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a59fabd441d22859"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('IoT_Modbus.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969c8f8886dbef26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Complete EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aee1e602ca5c766b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine 'date' and 'time' into a single datetime column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a9dccfe7b750f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0c2e5922a26caa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract time features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a533a2b1f01a79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['minute'] = data['datetime'].dt.minute\n",
    "data['second'] = data['datetime'].dt.second\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0beb939e4303617"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time series models need to ensure that the data set is arranged in time order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfdf8be0feb86374"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort the data by datetime\n",
    "data = data.sort_values(by='datetime')\n",
    "\n",
    "# Drop the original date, time, and timestamp columns\n",
    "data.drop(['date', 'time', 'datetime', 'type'], axis=1, inplace=True)\n",
    "\n",
    "# Adjust feature order\n",
    "order = ['year', 'month', 'day', 'hour', 'minute', 'second', 'dayofweek', 'FC1_Read_Input_Register', 'FC2_Read_Discrete_Value', 'FC3_Read_Holding_Register', 'FC4_Read_Coil', 'label']\n",
    "data = data[order].astype('int32')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87cbc212dbe19442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset (Sequential Split)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "347aaeb8bf6dd766"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate split points\n",
    "split_idx = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data set, keeping order\n",
    "train_data = data.iloc[:split_idx]\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = data.iloc[split_idx:]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f9a3e7015aaf6cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing (Normalization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f2fffdb83cab7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_columns = [col for col in X_train.columns if col != 'label']\n",
    "scaler = StandardScaler()\n",
    "X_train[feature_columns] = scaler.fit_transform(X_train[feature_columns]).astype('float32')\n",
    "X_test[feature_columns] = scaler.transform(X_test[feature_columns]).astype('float32')\n",
    "X_train.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "485e69a0e89e7b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execution model\n",
    "## Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c12c1b7fb50ea4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LightweightMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_size, width_multiplier=1.0):\n",
    "        super(LightweightMLP, self).__init__()\n",
    "        # Adjust hidden size based on the width multiplier\n",
    "        adjusted_hidden_size = int(hidden_size * width_multiplier)\n",
    "        \n",
    "        self.linear_1 = nn.Linear(input_dim, adjusted_hidden_size)\n",
    "        self.linear_2 = nn.Linear(adjusted_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        temp = F.relu(self.linear_1(x))\n",
    "        return self.linear_2(temp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ef4fe25ff764a21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3417f767ae1b5015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_num = X_train.shape[1]\n",
    "hidden_neurons_num = 512\n",
    "output_neurons_num = 1\n",
    "lstm_num_layers = 2\n",
    "multiplier = 0.5\n",
    "\n",
    "model = LightweightMLP(features_num, hidden_neurons_num, output_neurons_num, lstm_num_layers, multiplier).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d66654954854fc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dd5b70589db43fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build loss functions and optimizers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da11cc42cf71b4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = torch.tensor([1, class_weights[1]], dtype=torch.float)\n",
    "criterion = nn.BCEWithLogitsLoss(torch.FloatTensor ([weights[1] / weights[0]])).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f491c38526ef20b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct Data Loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b12e726d70842c15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "X_train_tensor = torch.tensor(X_train.values).float().unsqueeze(1).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values).float().unsqueeze(1).to(device)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "578fb1053dfb20ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677881d18ae0a8bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "pbar = tqdm(total=num_epochs)\n",
    "loss_list = [None] * num_epochs\n",
    "acc_list = [None] * num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    times = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        # FP\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # BP and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate indicators\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "            # Calculate indicators\n",
    "            y = labels.cpu().numpy()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += accuracy_score(y, predictions)\n",
    "            times += 1\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = running_accuracy / times\n",
    "    loss_list[epoch] = epoch_loss\n",
    "    acc_list[epoch] = accuracy\n",
    "    \n",
    "    pbar.update(1)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Accuracy: {accuracy}')\n",
    "pbar.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "234ca3f008e97e4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualizing the training process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a90b287ae5db1a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Draw accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(acc_list, label='Training Accuracy')\n",
    "plt.title('Training Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7bab09ae6142362b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unseen test set performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bc101f20737968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test.values).float().unsqueeze(1).to(device)\n",
    "\n",
    "model.eval()\n",
    "outputs = model(X_test_tensor)\n",
    "with torch.no_grad():\n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    predictions = (probabilities > 0.5).float().cpu().numpy()\n",
    "\n",
    "    # Calculate indicators\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy: \", acc, \", Precision: \", precision, \", Recall: \", recall, \", F1: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ff3af552cbe05e41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37bb5c5380a6d9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_folder = \"save_model\"\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_filename = f\"model_rnn_{current_time}.pt\"\n",
    "full_path = os.path.join(save_folder, model_filename)\n",
    "torch.save(model.state_dict(), full_path)\n",
    "\n",
    "print(\"Model saved as:\", full_path)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e0e155fdfdd5bb14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
